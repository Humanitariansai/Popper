import pandas as pd
from validators import BasicDataValidationAgent

# --- Additional agents ---
from popper_agents import sampling_agent, consistency_agent, data_integrity_agent as popper_data_integrity

from popper_visualisation import (
    plot_confusion_matrix_binary, plot_roc_pr, plot_calibration_curve, plot_feature_importance,
    plot_fairness_bars, plot_robustness_curve
)
from report_utils import html_img_tag, html_table_from_dict, html_table_from_nested_dict
import matplotlib.pyplot as plt
import os
import numpy as np



def main():
    # 4. Feature importance (restored)
    df = pd.read_csv("loan_data_set.csv")
    outdir = "validation_report_outputs"
    os.makedirs(outdir, exist_ok=True)
    html = ["<html><head><title>Data Validation Report</title></head><body>"]
    html.append("<h1>Data Validation Report</h1>")
    html.append("<p>This report was generated by running the full Popper agent pipeline, mirroring the logic and outputs of the datavalidation_popper.ipynb notebook.</p>")

    # Data preview
    html.append("<h2>Step 1: Data Preview</h2>")
    html.append("<p>First 10 rows of the input dataset:</p>")
    html.append(df.head(10).to_html(border=1, index=False))

    # Label inference (as in notebook)
    html.append("<h2>Step 2: Label Inference</h2>")
    CANDIDATE_LABELS = ["label","target","y","approved","default","churn","loan_status","is_fraud","premium","price","outcome","response","Loan_Status","Outcome"]
    def infer_label_col(df):
        for c in CANDIDATE_LABELS:
            if c in df.columns: return c
        last = df.columns[-1]
        if not any(tok in last.lower() for tok in ["id","uuid","guid","hash"]): return last
        return None
    label_col = infer_label_col(df)
    html.append(f"<b>Inferred label column:</b> <b>{label_col}</b><br>")
    if label_col:
        y = df[label_col]
        html.append(f"<b>Label dtype:</b> {y.dtype} | <b>Unique values:</b> {y.nunique(dropna=True)}")
        if not pd.api.types.is_numeric_dtype(y):
            html.append("<br>Label appears categorical; encoding will be applied.")
    else:
        html.append("<b>Label column could not be inferred.</b>")

    # Drop obvious IDs
    html.append("<h2>Step 3: Drop Obvious ID Columns</h2>")
    id_like = [c for c in df.columns if any(tok in c.lower() for tok in ["id","uuid","guid","hash"])]
    if id_like:
        html.append(f"Dropped id-like columns: {id_like}")
        df = df.drop(columns=id_like)
    else:
        html.append("No obvious ID columns found.")

    # Drop label col from features
    html.append("<h2>Step 4: Feature/Label Split and Encoding</h2>")
    X = df.drop(columns=[label_col]) if label_col else df.copy()
    y = df[label_col] if label_col else None
    if y is not None and not pd.api.types.is_numeric_dtype(y):
        html.append("<br>Label encoded as categorical codes.")
        y = pd.Categorical(y).codes
    X = X.select_dtypes(include=[float, int, np.number])
    # Impute missing values (median) for numeric columns
    from sklearn.impute import SimpleImputer
    imp = SimpleImputer(strategy='median')
    X = pd.DataFrame(imp.fit_transform(X), columns=X.columns)
    html.append(f"<br>Feature columns used: {list(X.columns)}")

    # Build baseline model (as in notebook)
    html.append("<h2>Step 5: Model Fitting</h2>")
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, random_state=7, stratify=None)
    model = LogisticRegression(max_iter=2000, solver="liblinear", class_weight="balanced")
    model.fit(Xtr, ytr)
    preds = model.predict(Xte)
    proba = None
    if hasattr(model, "predict_proba"):
        try:
            proba = model.predict_proba(Xte)[:, -1]
        except Exception:
            proba = None
    html.append("Model fitted and predictions made on test split.")

    # Run agents and collect results
    html.append("<h2>Step 6: Agent Results and Data Validation</h2>")
    agent = BasicDataValidationAgent()
    results = agent.validate_dataset(df)
    pari = popper_data_integrity(df)
    html.append("<h3>Data Integrity Agent (Dict):</h3>")
    html.append(f'<pre>{results}</pre>')
    html.append("<h3>Popper Agent Result (AgentResult):</h3>")
    html.append(f'<pre>{pari.to_dict()}</pre>')

    # Summary tables
    html.append("<h2>Step 7: Summary Tables</h2>")
    html.append(html_table_from_nested_dict(results.get('missing_values', {}), title="Missing Values"))
    html.append(html_table_from_nested_dict(results.get('outliers', {}), title="Outliers"))
    html.append(html_table_from_nested_dict(results.get('distributions', {}), title="Distributions"))
    html.append(html_table_from_dict(results.get('summary', {}), title="Summary"))

    # --- Generate and save Popper agent plots ---
    html.append("<h2>Step 8: Popper Agent Visualizations</h2>")
    img_files = []
    plt.ioff()
    # 1. Confusion matrix
    img1 = os.path.join(outdir, "confusion_matrix.png")
    plot_confusion_matrix_binary(yte, preds, save_path=img1)
    if os.path.exists(img1):
        img_files.append(("Confusion Matrix", img1))
    # 2. ROC/PR curves
    if proba is not None:
        roc_path = os.path.join(outdir, "roc_pr_roc.png")
        pr_path = os.path.join(outdir, "roc_pr_pr.png")
        plot_roc_pr(yte, proba, save_prefix=os.path.join(outdir, "roc_pr"))
        if os.path.exists(roc_path):
            img_files.append(("ROC Curve", roc_path))
        if os.path.exists(pr_path):
            img_files.append(("Precision-Recall Curve", pr_path))
        # 3. Calibration curve
        img3 = os.path.join(outdir, "calibration_curve.png")
        plot_calibration_curve(yte, proba, save_path=img3)
        if os.path.exists(img3):
            img_files.append(("Calibration Curve", img3))
    # 4. Feature importance
    # Generate and save feature importance plot (with error handling)
    try:
        feat_imp_path = os.path.join(outdir, "feature_importance.png")
        plot_feature_importance(model, Xtr, ytr, task="classification", save_path=feat_imp_path)
        if os.path.exists(feat_imp_path):
            img_files.append(("Feature Importance (Permutation)", feat_imp_path))
    except Exception as e:
        print(f"Feature importance plot failed: {e}")
    # 5. Fairness bar plots (if sensitive columns exist)
    candidates = ["Gender","Sex","Married","Education","Property_Area","race","ethnicity","age","age_group","zip","zipcode","state","country"]
    sens_cols = [c for c in candidates if c in df.columns]
    fairness_imgs = []
    if sens_cols:
        fairness_imgs = plot_fairness_bars(Xte, yte, preds, proba, sens_cols, outdir=outdir)
        img_files.extend(fairness_imgs)
    # 6. Robustness curve
    rob = plot_robustness_curve(model, Xte, yte, task="classification", outdir=outdir)
    if rob:
        img_files.append(rob)

    for title, img in img_files:
        html.append(f'<h3>{title}</h3>' + html_img_tag(img))
    html.append("</body></html>")
    html_path = os.path.join(outdir, "validation_report.html")
    with open(html_path, "w") as f:
        f.write("\n".join(html))
    print(f"\nHTML report generated: {html_path}")


if __name__ == "__main__":
    main()
