{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpY3xIzrUFeK",
        "outputId": "1683b3cb-236d-4648-f4f9-0920e94a8ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import Entrez\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# NCBI requirement — use your own email here\n",
        "Entrez.email = \"vtyag@illinois.edu\"\n",
        "\n",
        "# Load the search queries from file\n",
        "df = pd.read_excel(\"/content/assertions_with_search_queries.xlsx\")\n",
        "\n",
        "def search_ncbi(keywords, db=\"pubmed\", retmax=5):\n",
        "    \"\"\"\n",
        "    Search NCBI (pubmed or bookshelf) and return top titles with IDs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query = keywords\n",
        "        handle = Entrez.esearch(db=db, term=query, retmax=retmax)\n",
        "        record = Entrez.read(handle)\n",
        "        handle.close()\n",
        "\n",
        "        id_list = record.get(\"IdList\", [])\n",
        "        if not id_list:\n",
        "            return []\n",
        "\n",
        "        handle = Entrez.esummary(db=db, id=\",\".join(id_list))\n",
        "        summaries = Entrez.read(handle)\n",
        "        handle.close()\n",
        "\n",
        "        results = []\n",
        "        for summary in summaries:\n",
        "            title = summary.get(\"Title\", \"No title\")\n",
        "            uid = summary.get(\"Id\", \"\")\n",
        "            results.append(f\"{title} (ID: {uid})\")\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        return [f\"Error: {str(e)}\"]\n",
        "\n",
        "# Loop over each query and get top 5 results from PubMed + Bookshelf\n",
        "pubmed_list = []\n",
        "books_list = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    query = row[\"search_query\"]\n",
        "\n",
        "    pubmed_results = search_ncbi(query, db=\"pubmed\", retmax=5)\n",
        "    bookshelf_results = search_ncbi(query, db=\"books\", retmax=5)\n",
        "\n",
        "    pubmed_list.append(pubmed_results)\n",
        "    books_list.append(bookshelf_results)\n",
        "\n",
        "    # Respect NCBI rate limits\n",
        "    time.sleep(0.4)\n",
        "\n",
        "# Add results to DataFrame\n",
        "df[\"pubmed_results\"] = pubmed_list\n",
        "df[\"bookshelf_results\"] = books_list\n",
        "\n",
        "# Save output\n",
        "df.to_excel(\"fact_checker_results.xlsx\", index=False)\n",
        "\n",
        "print(\"Search complete. Results saved to fact_checker_results.xlsx\")\n"
      ],
      "metadata": {
        "id": "k9gx67OMQy1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bde387-cfa2-4e89-e6d5-d26e4cd36bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search complete. Results saved to fact_checker_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "from Bio import Entrez\n",
        "import google.generativeai as genai\n",
        "\n",
        "# -------------------------\n",
        "# CONFIGURATION\n",
        "# -------------------------\n",
        "Entrez.email = \"vtyag@illinois.edu\"  # Required by NCBI\n",
        "GOOGLE_API_KEY = \"AIzaSyBFbz5zLf3ClIq6rGbjOlve1H6kGhCHMdg\"   # Replace with your Gemini API Key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "MODEL = \"gemini-2.5-flash\"\n",
        "\n",
        "# -------------------------\n",
        "# FUNCTIONS\n",
        "# -------------------------\n",
        "def extract_ids_from_results(results_list):\n",
        "    \"\"\"\n",
        "    Extract NCBI IDs from results list like:\n",
        "    'Title (ID: 12345678)' → 12345678\n",
        "    \"\"\"\n",
        "    ids = []\n",
        "    if isinstance(results_list, str):\n",
        "        try:\n",
        "            results_list = eval(results_list)\n",
        "        except:\n",
        "            results_list = []\n",
        "    if isinstance(results_list, list):\n",
        "        for r in results_list:\n",
        "            match = re.search(r\"\\(ID:\\s*(\\d+)\\)\", r)\n",
        "            if match:\n",
        "                ids.append(match.group(1))\n",
        "    return ids\n",
        "\n",
        "def fetch_ncbi_documents(id_list, db):\n",
        "    \"\"\"\n",
        "    Fetch abstracts or summaries from NCBI PubMed or Bookshelf.\n",
        "    \"\"\"\n",
        "    if not id_list:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        handle = Entrez.efetch(db=db, id=\",\".join(id_list), rettype=\"abstract\", retmode=\"text\")\n",
        "        docs = handle.read()\n",
        "        handle.close()\n",
        "        return [docs]\n",
        "    except Exception as e:\n",
        "        return [f\"Error fetching from {db}: {e}\"]\n",
        "\n",
        "def fact_check_with_gemini(assertion, evidence_text):\n",
        "    \"\"\"\n",
        "    Send assertion + evidence to Gemini 2.5 Flash to verify.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a scientific fact-checking assistant.\n",
        "    Given the following scientific assertion:\n",
        "\n",
        "    Assertion:\n",
        "    {assertion}\n",
        "\n",
        "    And the following evidence from scientific literature:\n",
        "    {evidence_text}\n",
        "\n",
        "    Task:\n",
        "    1. Determine if the assertion is factually correct, incorrect, or partially correct.\n",
        "    2. Provide a brief reasoning.\n",
        "    3. Return the answer in JSON format:\n",
        "       {{\n",
        "         \"verdict\": \"Factually correct / Incorrect / Partially correct\",\n",
        "         \"reasoning\": \"Short reasoning here\"\n",
        "       }}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = genai.GenerativeModel(MODEL).generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# -------------------------\n",
        "# MAIN PIPELINE\n",
        "# -------------------------\n",
        "# Load your fact checker search results\n",
        "df = pd.read_excel(\"fact_checker_results.xlsx\")\n",
        "\n",
        "final_verdicts = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    assertion = row[\"statement_text\"]\n",
        "\n",
        "    # Extract PubMed & Bookshelf IDs\n",
        "    pubmed_ids = extract_ids_from_results(row[\"pubmed_results\"])\n",
        "    books_ids = extract_ids_from_results(row[\"bookshelf_results\"])\n",
        "\n",
        "    # Fetch documents\n",
        "    pubmed_docs = fetch_ncbi_documents(pubmed_ids, db=\"pubmed\")\n",
        "    books_docs = fetch_ncbi_documents(books_ids, db=\"books\")\n",
        "\n",
        "    # Combine evidence\n",
        "    all_evidence = \"\\n\\n\".join(pubmed_docs + books_docs)\n",
        "\n",
        "    # Fact check with Gemini\n",
        "    verdict_json = fact_check_with_gemini(assertion, all_evidence)\n",
        "\n",
        "    final_verdicts.append(verdict_json)\n",
        "\n",
        "    # NCBI rate limiting\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# Add verdicts to DataFrame\n",
        "df[\"fact_check_verdict\"] = final_verdicts\n",
        "\n",
        "# Save results\n",
        "df.to_excel(\"fact_checker_with_verdicts.xlsx\", index=False)\n",
        "\n",
        "print(\"Fact checking complete. Results saved to fact_checker_with_verdicts.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XKU2mWXJ-1g2",
        "outputId": "333ec6bb-7c35-404a-c9d0-8b6ab295803a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fact checking complete. Results saved to fact_checker_with_verdicts.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "id": "jkC1nH0SBVSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6fd0ce1-8f52-4262-befa-4ddd5a364575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
            "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m148.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import Entrez\n",
        "\n",
        "# Always include your email per NCBI policy\n",
        "Entrez.email = \"vtyag@illinois.edu\"\n",
        "\n",
        "# Your query\n",
        "query = \"present-day prokaryotes eukaryotes descended ancestor single\"\n",
        "\n",
        "# Search PubMed\n",
        "print(\"Searching PubMed...\")\n",
        "handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=10)\n",
        "pubmed_results = Entrez.read(handle)\n",
        "handle.close()\n",
        "pubmed_ids = pubmed_results[\"IdList\"]\n",
        "print(\"PubMed IDs:\", pubmed_ids)\n",
        "\n",
        "# Fetch summaries for PubMed IDs\n",
        "if pubmed_ids:\n",
        "    handle = Entrez.esummary(db=\"pubmed\", id=\",\".join(pubmed_ids))\n",
        "    pubmed_summaries = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    print(\"\\nPubMed Summaries:\")\n",
        "    for summary in pubmed_summaries:\n",
        "        print(\"-\", summary.get(\"Title\", \"No title\"))\n",
        "\n",
        "# Search NCBI Bookshelf\n",
        "print(\"\\nSearching Bookshelf...\")\n",
        "handle = Entrez.esearch(db=\"books\", term=query, retmax=10)\n",
        "books_results = Entrez.read(handle)\n",
        "handle.close()\n",
        "books_ids = books_results[\"IdList\"]\n",
        "print(\"Bookshelf IDs:\", books_ids)\n",
        "\n",
        "# Fetch summaries for Bookshelf IDs\n",
        "# Fetch summaries for Bookshelf IDs\n",
        "if books_ids:\n",
        "    handle = Entrez.esummary(db=\"books\", id=\",\".join(books_ids))\n",
        "    books_summaries = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    print(\"\\nBookshelf Summaries:\")\n",
        "    for summary in books_summaries:\n",
        "        print(\"-\", summary.get(\"Title\", \"No title\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI6vRrR6Dux1",
        "outputId": "9d8c6897-8e76-4bbf-b2d4-353faa4487d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching PubMed...\n",
            "PubMed IDs: []\n",
            "\n",
            "Searching Bookshelf...\n",
            "Bookshelf IDs: ['1603254', '1599746']\n",
            "\n",
            "Bookshelf Summaries:\n",
            "- THE ORIGIN AND EVOLUTION OF CELLS\n",
            "- The Origin and Evolution of Cells\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import Entrez\n",
        "\n",
        "# Always include your email per NCBI policy\n",
        "Entrez.email = \"vtyag@illinois.edu\"\n",
        "\n",
        "# Your query\n",
        "query = \"DNA production cellular proteins carries genetic\"\n",
        "\n",
        "# Search PubMed\n",
        "print(\"Searching PubMed...\")\n",
        "handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=10)\n",
        "pubmed_results = Entrez.read(handle)\n",
        "handle.close()\n",
        "pubmed_ids = pubmed_results[\"IdList\"]\n",
        "print(\"PubMed IDs:\", pubmed_ids)\n",
        "\n",
        "# Fetch summaries for PubMed IDs\n",
        "if pubmed_ids:\n",
        "    handle = Entrez.esummary(db=\"pubmed\", id=\",\".join(pubmed_ids))\n",
        "    pubmed_summaries = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    print(\"\\nPubMed Summaries:\")\n",
        "    for summary in pubmed_summaries:\n",
        "        print(\"-\", summary.get(\"Title\", \"No title\"))\n",
        "\n",
        "# Search NCBI Bookshelf\n",
        "print(\"\\nSearching Bookshelf...\")\n",
        "handle = Entrez.esearch(db=\"books\", term=query, retmax=10)\n",
        "books_results = Entrez.read(handle)\n",
        "handle.close()\n",
        "books_ids = books_results[\"IdList\"]\n",
        "print(\"Bookshelf IDs:\", books_ids)\n",
        "\n",
        "# Fetch summaries for Bookshelf IDs\n",
        "# Fetch summaries for Bookshelf IDs\n",
        "if books_ids:\n",
        "    handle = Entrez.esummary(db=\"books\", id=\",\".join(books_ids))\n",
        "    books_summaries = Entrez.read(handle)\n",
        "    handle.close()\n",
        "    print(\"\\nBookshelf Summaries:\")\n",
        "    for summary in books_summaries:\n",
        "        print(\"-\", summary.get(\"Title\", \"No title\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7XQc61OFLk1",
        "outputId": "fa5cc250-699a-475f-8c12-e859757c4aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching PubMed...\n",
            "PubMed IDs: ['40748513', '40691627', '40629055', '40623929', '40608358', '40598996', '40597313', '40597040', '40560800', '40558095']\n",
            "\n",
            "PubMed Summaries:\n",
            "- Loss of MALT1 Function in a Patient With Combined Immunodeficiency: a Novel Pathogenic Variant and Immunological Insights.\n",
            "- \"Small extracellular vesicles: messengers at the service of breast cancer agenda in the primary and distant microenvironments\".\n",
            "- Extremely low-frequency electromagnetic field (ELF-EMF) enhances mitochondrial energy production in NARP cybrids.\n",
            "- [Exploration of the pathogenic mechanism of a novel c.661_664dup (p.P222Lfs*60) variant of SOX10 gene].\n",
            "- Conjugative delivery of toxin genes ccdB and kil confers synergistic killing of bacterial recipients.\n",
            "- Development of a CRISPR/Cas9 RNP-mediated genetic engineering system in Paecilomyces variotii.\n",
            "- Outer membrane vesicles of Glaesserlla parasuis activate the endosomal cGAS-STING-IRF3 pathway through nucleic acid payload delivery: a biological perspective on host defense protocol optimization.\n",
            "- Molecular characteristics of hepatitis B virus among students and pregnant women in Chad.\n",
            "- Extracellular Vesicles From Xylella fastidiosa Carry sRNAs and Genomic Islands, Suggesting Roles in Recipient Cells.\n",
            "- Experimental and evolutionary evidence for horizontal transfer of an envelope fusion protein gene between thogotoviruses and baculoviruses.\n",
            "\n",
            "Searching Bookshelf...\n",
            "Bookshelf IDs: ['5767406', '5762778', '5753468', '5744304', '5677048', '5671246', '5663114', '5652958', '5652902', '5606894']\n",
            "\n",
            "Bookshelf Summaries:\n",
            "- 2.. GENE ADDITION TECHNIQUES\n",
            "- Clinical Significance\n",
            "- 3.2. EVIDENCE FOR EFFECTS ON THE RESPIRATORY SYSTEM\n",
            "- 4.. Mechanistic Evidence\n",
            "- RISK FACTORS\n",
            "- TYPES OF COVID-19 VACCINES\n",
            "- Background\n",
            "- The Food Forum 30th Anniversary: Proceedings of a Symposium\n",
            "- COMMONALITIES ACROSS AUTOIMMUNE DISEASES\n",
            "- DELAYED PUBERTY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tavily-python"
      ],
      "metadata": {
        "id": "b10B7kOuEHTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
        "\n",
        "from tavily import TavilyClient\n",
        "\n",
        "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "\n",
        "query = \"give link for ncbi that talks about 'Ribosomes approximately diameter'\"\n",
        "\n",
        "search_results = tavily.search(query=query)\n",
        "\n",
        "print(search_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "sAO91gXLbyiK",
        "outputId": "5e555393-409c-4df4-a8f7-73ba4972404c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tavily'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1898844725.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TAVILY_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"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\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtavily\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTavilyClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtavily\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTavilyClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TAVILY_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tavily'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}